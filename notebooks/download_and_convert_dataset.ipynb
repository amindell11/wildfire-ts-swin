{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WildfireSpreadTS: Download and Convert to HDF5\n",
        "\n",
        "This notebook downloads the WildfireSpreadTS dataset from Zenodo and converts it to HDF5 format for faster training. Run this **once** on Colab, then save the HDF5 output to Google Drive so you can reuse it across sessions.\n",
        "\n",
        "**Requirements:**\n",
        "- ~50 GB free disk for download + extraction (Colab Pro recommended for larger disk)\n",
        "- Or save directly to Google Drive (slower I/O, but persists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive (optional but recommended)\n",
        "\n",
        "Mount Drive to persist the dataset. If you skip this, data will be lost when the runtime disconnects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure paths\n",
        "\n",
        "- **`USE_DRIVE`**: Set to `True` to save the dataset to Google Drive (persists across sessions). Set to `False` to use Colab's local disk (faster, but lost on disconnect).\n",
        "- **`DRIVE_BASE`**: Base path in Drive when `USE_DRIVE=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "USE_DRIVE = True  # Set False to use /content only (faster, but ephemeral)\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/wildfire_dataset\"\n",
        "\n",
        "if USE_DRIVE:\n",
        "    BASE_DIR = DRIVE_BASE\n",
        "else:\n",
        "    BASE_DIR = \"/content/wildfire_dataset\"\n",
        "\n",
        "HDF5_DIR = f\"{BASE_DIR}/hdf5\"    # Converted HDF5 output\n",
        "ZIP_PATH = f\"{BASE_DIR}/WildfireSpreadTS.zip\"\n",
        "\n",
        "!mkdir -p \"{BASE_DIR}\" \"{HDF5_DIR}\"\n",
        "print(f\"HDF5_DIR: {HDF5_DIR}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download dataset from Zenodo\n",
        "\n",
        "The dataset is ~48 GB. This may take 30–60+ minutes depending on connection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ZENODO_URL = \"https://zenodo.org/records/8006177/files/WildfireSpreadTS.zip?download=1\"\n",
        "\n",
        "if not Path(ZIP_PATH).exists():\n",
        "    !wget -O \"{ZIP_PATH}\" \"{ZENODO_URL}\"\n",
        "else:\n",
        "    print(f\"Zip already exists at {ZIP_PATH}, skipping download.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 4. Extract the zip archive\n",
        "\n",
        "Extraction may take 10–20 minutes. The zip contains GeoTIFF files organized by year and fire event."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "!unzip -o \"{ZIP_PATH}\" -d \"{BASE_DIR}\"\n",
        "# Zip extracts to BASE_DIR/WildfireSpreadTS/{2018,2019,2020,2021}/\n",
        "DATA_DIR = f\"{BASE_DIR}/WildfireSpreadTS\"\n",
        "print(f\"Extraction complete. Data at: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Clone WildfireSpreadTS and install dependencies\n",
        "\n",
        "The conversion script lives in the original WildfireSpreadTS repo. We need it for `CreateHDF5Dataset.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!git clone https://github.com/SebastianGer/WildfireSpreadTS.git /content/WildfireSpreadTS\n",
        "%cd /content/WildfireSpreadTS\n",
        "!pip install -q rasterio h5py numpy torch tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Convert TIF to HDF5\n",
        "\n",
        "This step reads each fire's GeoTIFFs and writes them to HDF5. HDF5 is ~2× the size but much faster to load during training. Expect 30–60+ minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
        "\n",
        "!python src/preprocess/CreateHDF5Dataset.py \\\n",
        "  --data_dir \"{DATA_DIR}\" \\\n",
        "  --target_dir \"{HDF5_DIR}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Optional: Free disk space\n",
        "\n",
        "After conversion, you can delete the zip and raw TIFs to free space. Only run this if you're sure the HDF5 conversion completed successfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Uncomment to delete zip and raw data (saves ~50+ GB)\n",
        "# !rm -f \"{ZIP_PATH}\"\n",
        "# !rm -rf \"{DATA_DIR}\"\n",
        "# print(\"Cleanup done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done\n",
        "\n",
        "Use `HDF5_DIR` as `--data_dir` when training:\n",
        "\n",
        "```bash\n",
        "python train_wildfire.py --data_dir /content/drive/MyDrive/wildfire_dataset/hdf5 --output_dir ./runs/wildfire --load_from_hdf5\n",
        "```\n",
        "\n",
        "(Adjust the path if you used a different `DRIVE_BASE` or `USE_DRIVE=False`.)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}